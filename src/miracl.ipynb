{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIRACL Dataset\n",
    "This Notebook demonstrates the setup of the MIRACL dataset for use in _PyTerrier_. The dataset is available on Huggingface and comprises two parts:\n",
    "\n",
    "1. **[miracl/miracl-corpus](https://huggingface.co/datasets/miracl/miracl-corpus)**: Contains the _corpus_ data.\n",
    "\n",
    "2. **[miracl/miracl](https://huggingface.co/datasets/miracl/miracl)**: Contains the _topics_ and _qrels_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "# %pip install python-terrier   # PyTerrier\n",
    "# %pip install datasets         # Hugging Face\n",
    "# %pip install tqdm             # tqdm progress bars\n",
    "# %pip install pandas           # pandas\n",
    "\n",
    "# somehow necessary on Mac, not sure about other OS\n",
    "# %pip install --upgrade jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pyterrier as pt\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyTerrier\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load miracl datasets\n",
    "lang='sw'   # choose language\n",
    "miracl_corpus = datasets.load_dataset('miracl/miracl-corpus', lang, trust_remote_code=True) # splits: train\n",
    "miracl_queries = datasets.load_dataset('miracl/miracl', lang, trust_remote_code=True)       # splits: train, dev, testA, testB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Limit amount of docs and queries (for testing with large datasets)\n",
    "# def limited_miracl_corpus_iter(limit=1000):\n",
    "#     count = 0\n",
    "#     for doc in tqdm(miracl_corpus['train'], desc=\"Processing Corpus\"):\n",
    "#         if count >= limit:\n",
    "#             break\n",
    "#         yield {\n",
    "#             'docno': doc['docid'], \n",
    "#             'title': doc['title'],\n",
    "#             'text': doc['text']\n",
    "#         }\n",
    "#         count += 1\n",
    "\n",
    "# # Preparing queries and qrels for PyTerrier\n",
    "# queries = []\n",
    "# qrels = []\n",
    "# for idx, data in enumerate(tqdm(miracl_queries[split], desc=\"Processing Queries and Qrels\")):\n",
    "#     if idx >= 10:  # Limit to first 10 queries\n",
    "#         break\n",
    "#     queries.append({'qid': data['query_id'], 'query': data['query']})\n",
    "#     for entry in data['positive_passages']:\n",
    "#         qrels.append({'qid': data['query_id'], 'docno': entry['docid'], 'label': 1})\n",
    "#     for entry in data['negative_passages']:\n",
    "#         qrels.append({'qid': data['query_id'], 'docno': entry['docid'], 'label': 0})\n",
    "#\n",
    "# queries_df = pd.DataFrame(queries)\n",
    "# qrels_df = pd.DataFrame(qrels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Queries and Qrels: 100%|██████████| 1901/1901 [00:00<00:00, 28588.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Choose split for queries dataset\n",
    "split = 'train'   # 'dev', 'train', 'testA', 'testB'\n",
    "\n",
    "# Corpus iterator\n",
    "def miracl_corpus_iter():\n",
    "    for doc in tqdm(miracl_corpus['train'], desc=\"Processing Corpus\"):\n",
    "        yield {\n",
    "            'docno': doc['docid'], \n",
    "            'title': doc['title'],\n",
    "            'text': doc['text']\n",
    "        }\n",
    "\n",
    "# Preparing queries and qrels for PyTerrier\n",
    "queries = []\n",
    "qrels = []\n",
    "for data in tqdm(miracl_queries[split], desc=\"Processing Queries and Qrels\"):\n",
    "    queries.append({'qid': data['query_id'], 'query': data['query']})\n",
    "    for entry in data['positive_passages']:\n",
    "        qrels.append({'qid': data['query_id'], 'docno': entry['docid'], 'label': 1})\n",
    "    for entry in data['negative_passages']:\n",
    "        qrels.append({'qid': data['query_id'], 'docno': entry['docid'], 'label': 0})\n",
    "\n",
    "\n",
    "queries_df = pd.DataFrame(queries)\n",
    "qrels_df = pd.DataFrame(qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Corpus:   0%|          | 0/131924 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:55:01.699 [ForkJoinPool-3-worker-1] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (30#5) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Corpus: 100%|██████████| 131924/131924 [00:04<00:00, 29884.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:55:07.482 [ForkJoinPool-3-worker-1] WARN org.terrier.structures.indexing.Indexer - Indexed 129 empty documents\n"
     ]
    }
   ],
   "source": [
    "# Indexing\n",
    "indexer = pt.IterDictIndexer(\"./miracl_index\", overwrite=True, blocks=True)\n",
    "index_ref = indexer.index(miracl_corpus_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 Single Query Testing/Debugging\n",
    "# bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\")\n",
    "# test_query_df = pd.DataFrame([{'qid': 'test', 'query': \"Testx\"}])\n",
    "# test_query_df['query'] = test_query_df['query'].str.replace(\"x\", \"omato\")\n",
    "# print(test_query_df)\n",
    "# test_results = bm25.transform(test_query_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25\n",
    "bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\")\n",
    "\n",
    "# Preprocessing\n",
    "queries_df['query'] = queries_df['query'].str.replace('?', '')  # remove question marks\n",
    "queries_df['query'] = queries_df['query'].str.replace(\"'\", \"\")  # remove apostrophes\n",
    "queries_df['query'] = queries_df['query'].str.replace(\"/\", \"\")  # remove slash\n",
    "queries_df['query'] = queries_df['query'].str.replace(\"!\", \"\")  # remove exclamation mark\n",
    "# add further replace statements should you encounter any \"Lexical Error\"\n",
    "\n",
    "# Apply BM25 to preprocessed queries\n",
    "results = bm25.transform(queries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name       map      ndcg\n",
      "0  BR(BM25)  0.211017  0.325033\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "eval_metrics = ['map', 'ndcg']\n",
    "eval_results = pt.Experiment(\n",
    "    [bm25],\n",
    "    queries_df,\n",
    "    qrels_df,\n",
    "    eval_metrics=eval_metrics,\n",
    "    #perquery=True\n",
    ")\n",
    "\n",
    "print(eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR-MIRACL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
